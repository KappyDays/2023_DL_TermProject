{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "CLASS_NUM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = \"datasets/real_data/test/\"\n",
    "\n",
    "# transform 적용\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "initial_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std)\n",
    "])\n",
    "\n",
    "test_data = datasets.ImageFolder(root=TEST_DATA_PATH, transform=initial_transform)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rhcrodhehd': 0, 'ckacnl': 1, 'rhacnl': 2, 'rodhehd': 3}\n",
      "698\n"
     ]
    }
   ],
   "source": [
    "# 불러온 data class 순서 확인\n",
    "print(test_data.class_to_idx)\n",
    "# 꽃개오동0 참취1 곰취2 개오동3\n",
    "print(len(test_data)) # 698개 떠야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  (CF_fc1): Linear(in_features=1000, out_features=512, bias=True)\n",
      "  (CF_fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "### model 불러오기\n",
    "model = torch.load('saved_model/epoch_4_val_0.94.pt') ## 불러올 model 지정\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def valid(model, validloader, batch_size, loss_function):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 모든 class f1-score 계산용\n",
    "        all_pre = np.array([])\n",
    "        all_lab = np.array([])\n",
    "        # 각 class별 f1-score 계산용\n",
    "        all_Rhc = []\n",
    "        all_cka = []\n",
    "        all_rha = []\n",
    "        all_ro = []\n",
    "        # 각 class별 accuracy 계산용\n",
    "        all_correct = [0, 0, 0, 0]\n",
    "        all_correct_num = [0, 0, 0, 0]\n",
    "        \n",
    "        for i, (image, label) in enumerate(tqdm(validloader)):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(image)\n",
    "            output = model.CF_fc1(output)\n",
    "            output = model.CF_fc2(output)\n",
    "            # output = model.module.CF_fc(output) # DP사용할 때\n",
    "            \n",
    "            valid_loss += loss_function(output, label).item()    \n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            # class별 accuracy 계산\n",
    "            my_pred = prediction.squeeze()\n",
    "            for idx, tm in enumerate(label):\n",
    "                if tm == my_pred[idx]:\n",
    "                    all_correct[tm] += 1\n",
    "                all_correct_num[tm] += 1\n",
    "                \n",
    "            # f1 score 계산 위한 결과저장\n",
    "            tmp = prediction.squeeze(-1).cpu().numpy()\n",
    "            tmp2 = label.cpu().numpy()\n",
    "            # class별 f1-score 계산\n",
    "\n",
    "                \n",
    "            # 모든 class의 f1-score 계산\n",
    "            if all_pre.size == 0:\n",
    "                all_pre = tmp\n",
    "            else:\n",
    "                all_pre = np.concatenate((all_pre,tmp))\n",
    "            if all_lab.size == 0:\n",
    "                all_lab = tmp2\n",
    "            else:\n",
    "                all_lab = np.concatenate((all_lab,tmp2))\n",
    "                \n",
    "        print(classification_report(all_lab, all_pre, digits=4))\n",
    "        # f1-score 계산 위한 class별 label 생성\n",
    "        # all_lab_Rhc = np.zeros_like(all_Rhc)\n",
    "        # all_lab_cka = np.zeros_like(all_cka) + 1\n",
    "        # all_lab_rha = np.zeros_like(all_rha) + 2\n",
    "        # all_lab_ro = np.zeros_like(all_ro) + 3\n",
    "    \n",
    "    # f1_score 계산해서 저장\n",
    "    # f1_score = []\n",
    "    # f1_score.append(f1_score(torch.from_numpy(np.array(all_Rhc)), torch.from_numpy(all_lab_Rhc), num_classes=1))\n",
    "    # f1_score.append(multiclass_f1_score(torch.from_numpy(np.array(all_cka)), torch.from_numpy(all_lab_cka), num_classes=1))\n",
    "    # f1_score.append(multiclass_f1_score(torch.from_numpy(np.array(all_rha)), torch.from_numpy(all_lab_rha), num_classes=1))\n",
    "    # f1_score.append(multiclass_f1_score(torch.from_numpy(np.array(all_ro)), torch.from_numpy(all_lab_ro), num_classes=1))\n",
    "    # f1_score.append(multiclass_f1_score(torch.from_numpy(all_pre), torch.from_numpy(all_lab), num_classes=4))\n",
    "    \n",
    "    # valid_loss /= (len(validloader.dataset) / batch_size)\n",
    "    # valid_accuracy = 100. * correct / len(validloader.dataset)\n",
    "    for j in range(4):\n",
    "        print(\"Class {0} accuracy : {1}\".format(j, (len(np.where((all_pre != j) & (all_lab != j))[0]) + \\\n",
    "            len(np.where((all_pre == j) & (all_lab == j))[0])) / len(all_lab)))\n",
    "    \n",
    "    return valid_loss, all_pre, all_lab#, valid_accuracy, f1_score, all_correct, all_correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]c:\\Users\\kser\\Anaconda3\\envs\\sgmse\\lib\\site-packages\\PIL\\Image.py:2896: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|██████████| 44/44 [02:08<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.9864    0.9571       147\n",
      "           1     0.9748    0.9915    0.9831       234\n",
      "           2     0.9753    0.9461    0.9605       167\n",
      "           3     0.9859    0.9333    0.9589       150\n",
      "\n",
      "    accuracy                         0.9670       698\n",
      "   macro avg     0.9664    0.9643    0.9649       698\n",
      "weighted avg     0.9678    0.9670    0.9670       698\n",
      "\n",
      "Class 0 accuracy : 0.9813753581661891\n",
      "Class 1 accuracy : 0.9885386819484241\n",
      "Class 2 accuracy : 0.9813753581661891\n",
      "Class 3 accuracy : 0.9828080229226361\n",
      "Class 0 accuracy : 0.9813753581661891\n",
      "Class 1 accuracy : 0.9885386819484241\n",
      "Class 2 accuracy : 0.9813753581661891\n",
      "Class 3 accuracy : 0.9828080229226361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, all_pre, all_lab = valid(model, test_data_loader, BATCH_SIZE, loss_function)\n",
    "\n",
    "\n",
    "for j in range(4):\n",
    "    print(\"Class {0} accuracy : {1}\".format(j, (len(np.where((all_pre != j) & (all_lab != j))[0]) + \\\n",
    "        len(np.where((all_pre == j) & (all_lab == j))[0])) / len(all_lab)))\n",
    "        \n",
    "print() # 145, 540 / 147, 551 0.9813\n",
    "        # 232, 458 / 234, 464 0.9885(len(np.where((all_pre != 2) & (all_lab != 2))[0]) + len(np.where((all_pre == 2) & (all_lab == 2))[0])) / len(all_lab)\n",
    "        # 0.9813 , 0.9885, 0.9813, 0.9828\n",
    "# print()\n",
    "# print(f\"test_accuracy: {test_accuracy} % f1-score: {f1_score}  ac: {ac}   acn: {acn}  class별 accuracy: {np.array(ac)/np.array(acn)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 accuracy : 0.9813753581661891\n",
      "Class 1 accuracy : 0.9885386819484241\n",
      "Class 2 accuracy : 0.9813753581661891\n",
      "Class 3 accuracy : 0.9828080229226361\n"
     ]
    }
   ],
   "source": [
    "for j in range(4):\n",
    "    print(\"Class {0} accuracy : {1}\".format(j, (len(np.where((all_pre != j) & (all_lab != j))[0]) + \\\n",
    "        len(np.where((all_pre == j) & (all_lab == j))[0])) / len(all_lab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.9864    0.9571       147\n",
      "           1     0.9748    0.9915    0.9831       234\n",
      "           2     0.9753    0.9461    0.9605       167\n",
      "           3     0.9859    0.9333    0.9589       150\n",
      "\n",
      "    accuracy                         0.9670       698\n",
      "   macro avg     0.9664    0.9643    0.9649       698\n",
      "weighted avg     0.9678    0.9670    0.9670       698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_lab, all_pre, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
